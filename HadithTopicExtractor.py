import torch
from transformers import AutoTokenizer, AutoModel
import numpy as np
from collections import Counter

# === Ð˜ÐÐ˜Ð¦Ð˜ÐÐ›Ð˜Ð—ÐÐ¦Ð˜Ð¯ ÐœÐžÐ”Ð•Ð›Ð˜ ===
MODEL_NAME = "asafaya/bert-base-arabic"  # ÐÑ€Ð°Ð±ÑÐºÐ¸Ð¹ BERT
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModel.from_pretrained(MODEL_NAME, output_attentions=True)
model.eval()

def extract_important_tokens(text, top_k=10):
    # Ð¢Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸Ñ
    inputs = tokenizer(text, return_tensors="pt", truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ attention: ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸Ð· [num_layers] Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ð¾Ð² [batch, num_heads, seq_len, seq_len]
    attentions = outputs.attentions

    # Ð£Ð´Ð°Ð»Ð¸Ð¼ CLS Ð¸ SEP, ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ ÐµÑÑ‚ÑŒ
    token_ids = inputs["input_ids"][0]
    tokens = tokenizer.convert_ids_to_tokens(token_ids)

    # Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð¿Ð¾ ÑÐ»Ð¾ÑÐ¼ Ð¸ Ð³Ð¾Ð»Ð¾Ð²Ð°Ð¼
    attn_stack = torch.stack(attentions)  # [layers, batch, heads, seq_len, seq_len]
    attn_mean = attn_stack.mean(dim=(0, 1, 2))  # [seq_len, seq_len]

    # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²: ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð¾Ð½Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÑŽÑ‚ Ð¾Ñ‚ Ð´Ñ€ÑƒÐ³Ð¸Ñ…
    token_importance = attn_mean.sum(dim=0).numpy()  # [seq_len]

    # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‚Ð¾ÐºÐµÐ½Ñ‹ Ñ Ð¸Ñ… Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒÑŽ
    token_score_pairs = [(tok, score) for tok, score in zip(tokens, token_importance)]

    # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐ»ÑƒÐ¶ÐµÐ±Ð½Ñ‹Ñ… Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²
    filtered = [(t, s) for t, s in token_score_pairs if t not in tokenizer.all_special_tokens and not t.startswith("##")]

    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¸ Ð²Ñ‹Ð±Ð¾Ñ€ top_k
    top_tokens = sorted(filtered, key=lambda x: x[1], reverse=True)[:top_k]
    return top_tokens

# === ÐŸÐ Ð˜ÐœÐ•Ð  ===
text = "Ù‚Ø§Ù„ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù…: Ø¥Ù†Ù…Ø§ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø¨Ø§Ù„Ù†ÙŠØ§Øª ÙˆØ¥Ù†Ù…Ø§ Ù„ÙƒÙ„ Ø§Ù…Ø±Ø¦ Ù…Ø§ Ù†ÙˆÙ‰"
keywords = extract_important_tokens(text, top_k=5)
print("ðŸ”‘ Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ñ‚Ð¾ÐºÐµÐ½Ñ‹:")
for token, score in keywords:
    print(f"{token:>10}: {score:.4f}")